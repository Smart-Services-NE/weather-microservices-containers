services:
  weather-api:
    build:
      context: ./WeatherService
      dockerfile: Dockerfile
    ports:
      - "8080:8080"
    environment:
      - ASPNETCORE_HTTP_PORTS=8080
      - ASPNETCORE_ENVIRONMENT=Development

  weather-api-dapr:
    image: "daprio/daprd:latest"
    command: [ "./daprd", "-app-id", "weather-api", "-app-port", "8080", "-app-channel-address", "weather-api", "-placement-host-address", "dapr-placement:50005", "-dapr-http-port", "3501", "-dapr-grpc-port", "50001", "--config", "/dapr/config.yaml", "--resources-path", "/dapr/policies", "--log-level", "debug" ]
    volumes:
      - "./dapr:/dapr"
    ports:
      - "3501:3501"
      - "50001:50001"
    depends_on:
      - weather-api
      - zipkin

  weather-web:
    build:
      context: ./WeatherWeb
      dockerfile: Dockerfile
    ports:
      - "8081:8081"
    environment:
      - ASPNETCORE_HTTP_PORTS=8081
      - ASPNETCORE_ENVIRONMENT=Development
    depends_on:
      - weather-api

  weather-web-dapr:
    image: "daprio/daprd:latest"
    command: [ "./daprd", "-app-id", "weather-web", "-app-port", "8081", "-app-channel-address", "weather-web", "-placement-host-address", "dapr-placement:50005", "-dapr-http-port", "3500", "-dapr-grpc-port", "50002", "--config", "/dapr/config.yaml", "--resources-path", "/dapr/policies", "--log-level", "debug" ]
    volumes:
      - "./dapr:/dapr"
    ports:
      - "3500:3500"
      - "50002:50002"
    depends_on:
      - weather-web
      - zipkin

  dapr-placement:
    image: "daprio/dapr:latest"
    command: [ "./placement", "-port", "50005" ]
    ports:
      - "50005:50005"

  zipkin:
    image: "openzipkin/zipkin"
    ports:
      - "9411:9411"

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
    ports:
      - "3000:3000"

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9093,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9093"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.5.0
    container_name: containerapp-kafka-connect-1
    depends_on:
      kafka:
        condition: service_healthy
      azurite:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      # Basic Connect configuration
      CONNECT_BOOTSTRAP_SERVERS: kafka:9093
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: "azurite-sink-group"

      # Storage topics (1 replica for local dev)
      CONNECT_CONFIG_STORAGE_TOPIC: "connect-configs"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: "connect-offsets"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: "connect-status"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1

      # JSON converters (no schema)
      CONNECT_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"

      # Plugin path
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"

      # Azure Storage credentials (for optional blob sink connector)
      AZURE_STORAGE_CONNECTION_STRING: ${AZURE_STORAGE_CONNECTION_STRING}
      AZURE_STORAGE_ACCOUNT: ${AZURE_STORAGE_ACCOUNT:-devstoreaccount1}
      AZURE_STORAGE_KEY: ${AZURE_STORAGE_KEY}

      # Logging
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO

    volumes:
      - ./kafka-connect/connectors:/usr/share/confluent-hub-components
      - ./kafka-connect/config:/etc/kafka-connect

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    networks:
      - default

    # Note: Kafka Connect is optional since NotificationService consumes directly from Kafka
    # To install Azure Blob Storage sink connector (optional):
    # confluent-hub install --no-prompt confluentinc/kafka-connect-azure-blob-storage:1.6.0
    command:
      - bash
      - -c
      - |
        echo "Kafka Connect ready for custom connectors..."
        echo "NotificationService consumes from Kafka and writes to Azurite Table Storage directly"
        /etc/confluent/docker/run

  notification-api:
    build:
      context: .
      dockerfile: NotificationService/Clients/WebApi/Dockerfile
    ports:
      - "8082:8080"
    environment:
      - ASPNETCORE_HTTP_PORTS=8080
      - ASPNETCORE_ENVIRONMENT=Development
      # Kafka Configuration (Confluent Cloud)
      - Kafka__BootstrapServers=${KAFKA_BOOTSTRAP_SERVERS:-kafka:9093}
      - Kafka__GroupId=${KAFKA_GROUP_ID:-notification-service}
      - Kafka__SecurityProtocol=${KAFKA_SECURITY_PROTOCOL:-}
      - Kafka__SaslMechanism=${KAFKA_SASL_MECHANISM:-}
      - Kafka__SaslUsername=${KAFKA_SASL_USERNAME:-}
      - Kafka__SaslPassword=${KAFKA_SASL_PASSWORD:-}
      # Schema Registry Configuration (Required for Avro deserialization)
      - Kafka__SchemaRegistryUrl=${KAFKA_SCHEMA_REGISTRY_URL:-}
      - Kafka__SchemaRegistryKey=${KAFKA_SCHEMA_REGISTRY_KEY:-}
      - Kafka__SchemaRegistrySecret=${KAFKA_SCHEMA_REGISTRY_SECRET:-}
      - Kafka__UseAvroConsumer=${KAFKA_USE_AVRO_CONSUMER:-true}
      # Email Configuration
      - Email__SmtpHost=smtp.gmail.com
      - Email__SmtpPort=587
      - Email__EnableSsl=true
      # Database
      - ConnectionStrings__NotificationDb=Data Source=/app/data/notifications.db
      # Telemetry
      - Zipkin__Endpoint=http://zipkin:9411/api/v2/spans
    depends_on:
      # Comment out kafka dependency when using Confluent Cloud
      # kafka:
      #   condition: service_healthy
      zipkin:
        condition: service_started
    volumes:
      - ./notification-data:/app/data
    networks:
      - default
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  notification-api-dapr:
    image: "daprio/daprd:latest"
    command:
      - "./daprd"
      - "-app-id"
      - "notification-api"
      - "-app-port"
      - "8080"
      - "-app-protocol"
      - "http"
      - "-app-channel-address"
      - "notification-api"
      - "-placement-host-address"
      - "dapr-placement:50005"
      - "-dapr-http-port"
      - "3502"
      - "-dapr-grpc-port"
      - "50003"
      - "--config"
      - "/dapr/config.yaml"
      - "--resources-path"
      - "/dapr/policies"
      - "--log-level"
      - "debug"
      - "--enable-metrics"
      - "true"
      - "--metrics-port"
      - "9090"
    volumes:
      - "./dapr:/dapr"
    ports:
      - "3502:3502"
      - "50003:50003"
    depends_on:
      notification-api:
        condition: service_healthy
    networks:
      - default

  azurite:
    image: mcr.microsoft.com/azure-storage/azurite:latest
    container_name: containerapp-azurite-1
    ports:
      - "10000:10000"  # Blob service
      - "10001:10001"  # Queue service
      - "10002:10002"  # Table service
    environment:
      - AZURITE_ACCOUNTS=devstoreaccount1:Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==
    volumes:
      - azurite-data:/data
    command: azurite --blobHost 0.0.0.0 --queueHost 0.0.0.0 --tableHost 0.0.0.0 --location /data --debug /data/debug.log
    networks:
      - default
    healthcheck:
      test: ["CMD-SHELL", "wget --spider -q http://localhost:10000 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

volumes:
  azurite-data:
